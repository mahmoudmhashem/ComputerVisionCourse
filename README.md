# Computer Vision Course
#### In this Course we will depend on the following two courses from TUM School of Computation, Information and Technology

1- [Introduction to Deep Learning](https://cvg.cit.tum.de/teaching/ws2024/i2dl)

2- [Computer Vision III: Detection, Segmentation and Tracking](https://cvg.cit.tum.de/teaching/ws2024/cv3)

## Week0
### Section
Revision for numpy arrays and Introduction to pytorch tensors

We will depend on the following two Notebooks

1- [Revision for numpy](https://nbviewer.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-2-Numpy.ipynb)

2- [introduction to pytorch tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)

## Week1
This week is depend on Lecture2 from Introduction to Deep Learning (IN2346) course at TUM School of Computation, Information and Technology.
And an medium Tutorial

### Medium Tutorial
[analytical-solution-of-linear-regression](https://medium.com/towards-data-science/analytical-solution-of-linear-regression-a0e870b038d5)

### MUT pdf Lecture:
[Linear Models](https://cvg.cit.tum.de/_media/teaching/ws2024/i2dl/2.linear.pdf)

### MUT recording video: 
[I2DL - Lecture 02: Machine Learning Basics](https://youtu.be/Ui7-QwAoHmA?si=6QYzoinM74muuJN_)


### Assignment:
Linear Regression implementation From scratch.

## Week2
This week is depend on Lecture3 from Introduction to Deep Learning (IN2346) course at TUM School of Computation, Information and Technology.

### MUT pdf Lecture:
[intro2nn](https://cvg.cit.tum.de/_media/teaching/ws2024/i2dl/3.intro2nn.pdf)

[optimization_and_backprop](https://cvg.cit.tum.de/_media/teaching/ws2024/i2dl/4.optimization_and_backprop.pdf)

### MUT recording video: 
[I2DL - Lecture 03: Introduction to Neural Networks](https://youtu.be/1cmdxeEDkd8?si=q9QKDaPYI7u1rpX3)

[I2DL - Lecture 04: Optimization and Backpropagation](https://youtu.be/2e1csSPTGPQ?si=XINo7gd8GQO64srV)

### Additional material
[Difference between partial and total derivatives](https://youtu.be/Kp7sSp5Kn7o?si=t2-MZmd1tu4OmUJJ)


### Section
A Gentle Introduction to torch.autograd

We will depend on the following one Notebook
[A Gentle Introduction to torch.autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)

### Assignment:
Computational Graph Implementation From scratch For Sigmoid Function ie (implement forward and backward function For Sigmoid function).
Note: Wrap your functions into a class called Sigmoid Class


